{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99eeae0-2a02-4af7-8793-d999e7089d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5c325a-af5d-4019-b6ba-e21ea417d324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87599 training examples\n",
      "Loaded 10570 development examples\n",
      "Vocabulary size: 50000\n"
     ]
    }
   ],
   "source": [
    "# Load processed data and vocabulary\n",
    "with open('../../data/q&a/vocab.pkl', 'rb') as f:\n",
    "    vocab_data = pickle.load(f)\n",
    "    word2idx = vocab_data['word2idx']\n",
    "    idx2word = vocab_data['idx2word']\n",
    "\n",
    "with open('../../data/q&a/train_processed.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open('../../data/q&a/dev_processed.pkl', 'rb') as f:\n",
    "    dev_data = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training examples\")\n",
    "print(f\"Loaded {len(dev_data)} development examples\")\n",
    "print(f\"Vocabulary size: {len(word2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d6b17f-54cd-4e70-8181-8ff226865f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, max_context_len=400, max_question_len=50):\n",
    "        # Filter out invalid examples\n",
    "        self.data = [ex for ex in data if ex['start_position'] >= 0 and ex['end_position'] >= 0]\n",
    "        self.max_context_len = max_context_len\n",
    "        self.max_question_len = max_question_len\n",
    "        print(f\"Filtered to {len(self.data)} valid examples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        \n",
    "        # Ensure positions are within bounds\n",
    "        start_pos = min(example['start_position'], self.max_context_len - 1)\n",
    "        end_pos = min(example['end_position'], self.max_context_len - 1)\n",
    "        \n",
    "        return {\n",
    "            'context_ids': torch.tensor(example['context_ids'][:self.max_context_len], dtype=torch.long),\n",
    "            'question_ids': torch.tensor(example['question_ids'][:self.max_question_len], dtype=torch.long),\n",
    "            'start_position': torch.tensor(start_pos, dtype=torch.long),\n",
    "            'end_position': torch.tensor(end_pos, dtype=torch.long),\n",
    "            'id': example['id']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e0078d-115f-4aaa-8ef2-4a83970273fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiDAF Model with attention Q&A Model\n",
    "class BiDAFModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=300, hidden_dim=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Word embeddings\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=word2idx['<PAD>'])\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Highway network for embeddings\n",
    "        self.highway = Highway(embed_dim, num_layers=2)\n",
    "        \n",
    "        # Contextual encoding layers\n",
    "        self.context_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, \n",
    "                                   bidirectional=True, dropout=dropout if dropout > 0 else 0)\n",
    "        self.question_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, \n",
    "                                    bidirectional=True, dropout=dropout if dropout > 0 else 0)\n",
    "        \n",
    "        # Attention weights\n",
    "        self.att_weight_c = nn.Linear(2 * hidden_dim, 1, bias=False)\n",
    "        self.att_weight_q = nn.Linear(2 * hidden_dim, 1, bias=False)  \n",
    "        self.att_weight_cq = nn.Linear(2 * hidden_dim, 1, bias=False)\n",
    "        \n",
    "        # Modeling layer\n",
    "        self.modeling_lstm1 = nn.LSTM(8 * hidden_dim, hidden_dim, batch_first=True,\n",
    "                                     bidirectional=True, dropout=dropout if dropout > 0 else 0)\n",
    "        self.modeling_lstm2 = nn.LSTM(2 * hidden_dim, hidden_dim, batch_first=True,\n",
    "                                     bidirectional=True, dropout=dropout if dropout > 0 else 0)\n",
    "        \n",
    "        # Output projections\n",
    "        self.start_linear = nn.Linear(10 * hidden_dim, 1)\n",
    "        self.end_linear = nn.Linear(10 * hidden_dim, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and len(param.shape) > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "    \n",
    "    def forward(self, context, question):\n",
    "        batch_size = context.size(0)\n",
    "        context_len = context.size(1)\n",
    "        question_len = question.size(1)\n",
    "        \n",
    "        # Masks\n",
    "        context_mask = (context != word2idx['<PAD>']).float()\n",
    "        question_mask = (question != word2idx['<PAD>']).float()\n",
    "        \n",
    "        # Embeddings with highway network\n",
    "        context_emb = self.embedding(context)\n",
    "        question_emb = self.embedding(question)\n",
    "        \n",
    "        context_emb = self.highway(context_emb)\n",
    "        question_emb = self.highway(question_emb)\n",
    "        \n",
    "        context_emb = self.embedding_dropout(context_emb)\n",
    "        question_emb = self.embedding_dropout(question_emb)\n",
    "        \n",
    "        # Contextual encoding\n",
    "        context_enc, _ = self.context_lstm(context_emb)  # (batch, context_len, 2*hidden)\n",
    "        question_enc, _ = self.question_lstm(question_emb)  # (batch, question_len, 2*hidden)\n",
    "        \n",
    "        # Attention Flow Layer\n",
    "        # Similarity matrix computation\n",
    "        similarity = self._compute_similarity(context_enc, question_enc)  # (batch, context_len, question_len)\n",
    "        \n",
    "        # Mask similarity scores\n",
    "        question_mask_expanded = question_mask.unsqueeze(1).expand(-1, context_len, -1)\n",
    "        similarity = similarity.masked_fill(question_mask_expanded == 0, -1e9)\n",
    "        \n",
    "        # Context-to-Question Attention\n",
    "        c2q_att = F.softmax(similarity, dim=2)  # (batch, context_len, question_len)\n",
    "        c2q = torch.bmm(c2q_att, question_enc)  # (batch, context_len, 2*hidden)\n",
    "        \n",
    "        # Question-to-Context Attention\n",
    "        max_similarity = torch.max(similarity, dim=2)[0]  # (batch, context_len)\n",
    "        q2c_att = F.softmax(max_similarity, dim=1)  # (batch, context_len)\n",
    "        q2c = torch.bmm(q2c_att.unsqueeze(1), context_enc)  # (batch, 1, 2*hidden)\n",
    "        q2c = q2c.expand(-1, context_len, -1)  # (batch, context_len, 2*hidden)\n",
    "        \n",
    "        # Query-aware context representation\n",
    "        G = torch.cat([\n",
    "            context_enc,\n",
    "            c2q, \n",
    "            context_enc * c2q,\n",
    "            context_enc * q2c\n",
    "        ], dim=2)  # (batch, context_len, 8*hidden)\n",
    "        \n",
    "        G = self.dropout(G)\n",
    "        \n",
    "        # Modeling Layer\n",
    "        M1, _ = self.modeling_lstm1(G)  # (batch, context_len, 2*hidden)\n",
    "        M2, _ = self.modeling_lstm2(M1)  # (batch, context_len, 2*hidden)\n",
    "        \n",
    "        # Output Layer\n",
    "        start_input = torch.cat([G, M1], dim=2)  # (batch, context_len, 10*hidden)\n",
    "        end_input = torch.cat([G, M2], dim=2)    # (batch, context_len, 10*hidden)\n",
    "        \n",
    "        start_logits = self.start_linear(start_input).squeeze(-1)  # (batch, context_len)\n",
    "        end_logits = self.end_linear(end_input).squeeze(-1)       # (batch, context_len)\n",
    "        \n",
    "        # Apply context mask\n",
    "        start_logits = start_logits.masked_fill(context_mask == 0, -1e9)\n",
    "        end_logits = end_logits.masked_fill(context_mask == 0, -1e9)\n",
    "        \n",
    "        return start_logits, end_logits\n",
    "    \n",
    "    def _compute_similarity(self, context_enc, question_enc):\n",
    "        \"\"\"Compute similarity matrix between context and question\"\"\"\n",
    "        batch_size, context_len, hidden_size = context_enc.size()\n",
    "        question_len = question_enc.size(1)\n",
    "        \n",
    "        # Expand tensors for element-wise operations\n",
    "        context_expanded = context_enc.unsqueeze(2).expand(-1, -1, question_len, -1)\n",
    "        question_expanded = question_enc.unsqueeze(1).expand(-1, context_len, -1, -1)\n",
    "        \n",
    "        # Element-wise product\n",
    "        elementwise_prod = context_expanded * question_expanded\n",
    "        \n",
    "        # Compute attention weights\n",
    "        alpha = (self.att_weight_c(context_expanded) + \n",
    "                self.att_weight_q(question_expanded) + \n",
    "                self.att_weight_cq(elementwise_prod))  # (batch, context_len, question_len, 1)\n",
    "        \n",
    "        return alpha.squeeze(-1)  # (batch, context_len, question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc15cf4-17ac-43e9-a980-62618170b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highway Network for better gradient flow\n",
    "class Highway(nn.Module):\n",
    "    def __init__(self, size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.nonlinear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
    "        self.linear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
    "        self.gate = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in range(self.num_layers):\n",
    "            gate = torch.sigmoid(self.gate[layer](x))\n",
    "            nonlinear = F.relu(self.nonlinear[layer](x))\n",
    "            linear = self.linear[layer](x)\n",
    "            x = gate * nonlinear + (1 - gate) * linear\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2d1c16-7275-4d7d-b5c9-a10526829c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0008\n",
    "NUM_EPOCHS = 3\n",
    "EMBED_DIM = 300\n",
    "HIDDEN_DIM = 128\n",
    "DROPOUT = 0.2\n",
    "MAX_GRAD_NORM = 5.0\n",
    "WARMUP_PROPORTION = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5204fcb-f590-4b1b-bd8c-42ff56d82058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 87599 valid examples\n",
      "Filtered to 10570 valid examples\n",
      "Training batches: 2738\n",
      "Development batches: 331\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "train_dataset = QADataset(train_data, max_context_len=400, max_question_len=50)\n",
    "dev_dataset = QADataset(dev_data, max_context_len=400, max_question_len=50)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Development batches: {len(dev_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43bdcc58-6753-46f6-aa18-130936b0e29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/ML/Projects/ai-powered-research-assistant/assistant-gpu/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 18,002,730\n",
      "Trainable parameters: 18,002,730\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = BiDAFModel(\n",
    "    vocab_size=len(word2idx),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968f932b-53c5-4a2b-b9cf-3265e4d8c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "total_steps = len(train_loader) * NUM_EPOCHS\n",
    "warmup_steps = int(total_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82e7f5d-eb4e-47b4-ae5f-5570bc1d70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps)))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ce26de-c47b-4952-a039-72cffbdaae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad33ed43-304d-440b-981a-3bcc975d7872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, train_loader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_starts = 0\n",
    "    correct_ends = 0\n",
    "    total_examples = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        context_ids = batch['context_ids'].to(device)\n",
    "        question_ids = batch['question_ids'].to(device)\n",
    "        start_positions = batch['start_position'].to(device)\n",
    "        end_positions = batch['end_position'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        start_logits, end_logits = model(context_ids, question_ids)\n",
    "        \n",
    "        # Calculate loss\n",
    "        start_loss = criterion(start_logits, start_positions)\n",
    "        end_loss = criterion(end_logits, end_positions)\n",
    "        loss = start_loss + end_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        start_preds = start_logits.argmax(dim=1)\n",
    "        end_preds = end_logits.argmax(dim=1)\n",
    "        \n",
    "        correct_starts += (start_preds == start_positions).sum().item()\n",
    "        correct_ends += (end_preds == end_positions).sum().item()\n",
    "        total_examples += start_positions.size(0)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Start Acc': f'{correct_starts/total_examples:.3f}',\n",
    "            'End Acc': f'{correct_ends/total_examples:.3f}',\n",
    "            'LR': f'{scheduler.get_last_lr()[0]:.6f}'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    start_acc = correct_starts / total_examples\n",
    "    end_acc = correct_ends / total_examples\n",
    "    \n",
    "    return avg_loss, start_acc, end_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74b7a884-52a8-4853-8ddd-423898851a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function  \n",
    "def evaluate_model(model, dev_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_starts = 0\n",
    "    correct_ends = 0\n",
    "    exact_matches = 0\n",
    "    total_examples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dev_loader, desc=\"Evaluating\"):\n",
    "            context_ids = batch['context_ids'].to(device)\n",
    "            question_ids = batch['question_ids'].to(device)\n",
    "            start_positions = batch['start_position'].to(device)\n",
    "            end_positions = batch['end_position'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            start_logits, end_logits = model(context_ids, question_ids)\n",
    "            \n",
    "            # Calculate loss\n",
    "            start_loss = criterion(start_logits, start_positions)\n",
    "            end_loss = criterion(end_logits, end_positions)\n",
    "            loss = start_loss + end_loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            start_preds = start_logits.argmax(dim=1)\n",
    "            end_preds = end_logits.argmax(dim=1)\n",
    "            \n",
    "            correct_starts += (start_preds == start_positions).sum().item()\n",
    "            correct_ends += (end_preds == end_positions).sum().item()\n",
    "            exact_matches += ((start_preds == start_positions) & (end_preds == end_positions)).sum().item()\n",
    "            total_examples += start_positions.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(dev_loader)\n",
    "    start_acc = correct_starts / total_examples\n",
    "    end_acc = correct_ends / total_examples\n",
    "    exact_acc = exact_matches / total_examples\n",
    "    \n",
    "    return avg_loss, start_acc, end_acc, exact_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb64a9a3-0b17-478f-a5c7-87f0825fac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████| 2738/2738 [18:05<00:00,  2.52it/s, Loss=6.7644, Start Acc=0.130, End Acc=0.140, LR=0.000593]\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████| 331/331 [00:24<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 7.3202, Start Acc: 0.1304, End Acc: 0.1397\n",
      "Dev - Loss: 6.3361, Start Acc: 0.2134, End Acc: 0.2268, Exact Acc: 0.1377\n",
      "New best model saved! Exact Acc: 0.1377\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████| 2738/2738 [19:23<00:00,  2.35it/s, Loss=3.7434, Start Acc=0.377, End Acc=0.412, LR=0.000296]\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████| 331/331 [00:22<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 4.6911, Start Acc: 0.3773, End Acc: 0.4116\n",
      "Dev - Loss: 4.4873, Start Acc: 0.4056, End Acc: 0.4434, Exact Acc: 0.2952\n",
      "New best model saved! Exact Acc: 0.2952\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████| 2738/2738 [28:34<00:00,  1.60it/s, Loss=3.3797, Start Acc=0.509, End Acc=0.553, LR=0.000000]\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████| 331/331 [01:12<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 3.5035, Start Acc: 0.5093, End Acc: 0.5529\n",
      "Dev - Loss: 4.3978, Start Acc: 0.4221, End Acc: 0.4594, Exact Acc: 0.3114\n",
      "New best model saved! Exact Acc: 0.3114\n",
      "\n",
      "Training completed!\n",
      "Best Dev Exact Accuracy: 0.3114\n",
      "Best Dev Loss: 4.3978\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_exact_acc = 0\n",
    "best_dev_loss = float('inf')\n",
    "patience = 2\n",
    "patience_counter = 0\n",
    "\n",
    "os.makedirs('../../models/qa/', exist_ok=True)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_start_acc, train_end_acc = train_epoch(model, train_loader, optimizer, scheduler)\n",
    "    \n",
    "    # Evaluate\n",
    "    dev_loss, dev_start_acc, dev_end_acc, dev_exact_acc = evaluate_model(model, dev_loader)\n",
    "    \n",
    "    print(f\"Train - Loss: {train_loss:.4f}, Start Acc: {train_start_acc:.4f}, End Acc: {train_end_acc:.4f}\")\n",
    "    print(f\"Dev - Loss: {dev_loss:.4f}, Start Acc: {dev_start_acc:.4f}, End Acc: {dev_end_acc:.4f}, Exact Acc: {dev_exact_acc:.4f}\")\n",
    "    \n",
    "    # Save best model based on exact accuracy\n",
    "    if dev_exact_acc > best_exact_acc:\n",
    "        best_exact_acc = dev_exact_acc\n",
    "        best_dev_loss = dev_loss\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'dev_loss': dev_loss,\n",
    "            'dev_exact_acc': dev_exact_acc,\n",
    "            'vocab': {'word2idx': word2idx, 'idx2word': idx2word},\n",
    "            'config': {\n",
    "                'vocab_size': len(word2idx),\n",
    "                'embed_dim': EMBED_DIM,\n",
    "                'hidden_dim': HIDDEN_DIM,\n",
    "                'dropout': DROPOUT\n",
    "            }\n",
    "        }, '../../models/qa/best_qa_model.pt')\n",
    "        \n",
    "        print(f\"New best model saved! Exact Acc: {dev_exact_acc:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best Dev Exact Accuracy: {best_exact_acc:.4f}\")\n",
    "print(f\"Best Dev Loss: {best_dev_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f088d4-3308-419d-bc73-cc58399ae3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
