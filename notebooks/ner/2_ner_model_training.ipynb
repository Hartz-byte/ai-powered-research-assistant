{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773e4d83-101c-4926-a16a-30511111016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/ML/Projects/ai-powered-research-assistant/assistant-gpu/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Paths & device\n",
    "DATA_DIR = '../../data/ner/'\n",
    "MODEL_DIR = '../../models/ner/'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f57128-9568-4d50-bc69-3fd7751df6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val sentences: 38367 / 9592\n",
      "Max sequence length: 35\n",
      "Vocab sizes - Words: 35179, POS: 43, Tags: 18\n"
     ]
    }
   ],
   "source": [
    "# Load arrays\n",
    "Xw_train = np.load(os.path.join(DATA_DIR, 'Xw_train.npy'))\n",
    "Xw_val = np.load(os.path.join(DATA_DIR, 'Xw_val.npy'))\n",
    "Xp_train = np.load(os.path.join(DATA_DIR, 'Xp_train.npy'))\n",
    "Xp_val = np.load(os.path.join(DATA_DIR, 'Xp_val.npy'))\n",
    "Yt_train = np.load(os.path.join(DATA_DIR, 'Yt_train.npy'))\n",
    "Yt_val = np.load(os.path.join(DATA_DIR, 'Yt_val.npy'))\n",
    "\n",
    "# Load vocabularies\n",
    "with open(os.path.join(DATA_DIR, 'word2idx.pkl'), 'rb') as f:\n",
    "    word2idx = pickle.load(f)\n",
    "with open(os.path.join(DATA_DIR, 'pos2idx.pkl'), 'rb') as f:\n",
    "    pos2idx = pickle.load(f)\n",
    "with open(os.path.join(DATA_DIR, 'tag2idx.pkl'), 'rb') as f:\n",
    "    tag2idx = pickle.load(f)\n",
    "\n",
    "# Create reverse mappings\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "idx2pos = {v: k for k, v in pos2idx.items()}\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}\n",
    "\n",
    "PAD_IDX = word2idx['<PAD>']\n",
    "UNK_IDX = word2idx['<UNK>']\n",
    "max_seq_len = Xw_train.shape[1]\n",
    "\n",
    "print(f'Train/Val sentences: {len(Xw_train)} / {len(Xw_val)}')\n",
    "print(f'Max sequence length: {max_seq_len}')\n",
    "print(f'Vocab sizes - Words: {len(word2idx)}, POS: {len(pos2idx)}, Tags: {len(tag2idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c260db00-65cd-41ca-a484-9ede20cb7baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1199, Val batches: 300\n"
     ]
    }
   ],
   "source": [
    "# Dataset & DataLoader\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, words, pos, tags):\n",
    "        self.words = torch.LongTensor(words)\n",
    "        self.pos = torch.LongTensor(pos)\n",
    "        self.tags = torch.LongTensor(tags)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.words[idx], self.pos[idx], self.tags[idx]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = NERDataset(Xw_train, Xp_train, Yt_train)\n",
    "val_dataset = NERDataset(Xw_val, Xp_val, Yt_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}, Val batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb721be-0f44-451e-9b39-de5a3c69953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native CRF Implementation\n",
    "class CRF(nn.Module):\n",
    "    \"\"\"Native CRF implementation without external dependencies\"\"\"\n",
    "    \n",
    "    def __init__(self, num_tags, batch_first=True):\n",
    "        super(CRF, self).__init__()\n",
    "        self.num_tags = num_tags\n",
    "        self.batch_first = batch_first\n",
    "        \n",
    "        # Transition parameters: transition[i][j] = score of transitioning from tag i to tag j\n",
    "        self.transitions = nn.Parameter(torch.randn(num_tags, num_tags))\n",
    "        \n",
    "        # Initialize transitions (don't allow transitions to PAD)\n",
    "        self.transitions.data[PAD_IDX, :] = -10000  # No transitions from PAD\n",
    "        self.transitions.data[:, PAD_IDX] = -10000  # No transitions to PAD\n",
    "    \n",
    "    def _compute_partition_function(self, emissions, mask):\n",
    "        \"\"\"Compute the partition function using forward algorithm\"\"\"\n",
    "        batch_size, seq_length, num_tags = emissions.size()\n",
    "        \n",
    "        # Initialize forward variables\n",
    "        forward_var = emissions[:, 0].clone()  # (batch_size, num_tags)\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            # Broadcast forward_var and transitions for batch processing\n",
    "            emit_score = emissions[:, i].unsqueeze(1)  # (batch_size, 1, num_tags)\n",
    "            trans_score = self.transitions.unsqueeze(0)  # (1, num_tags, num_tags)\n",
    "            next_tag_var = forward_var.unsqueeze(2) + trans_score + emit_score\n",
    "            \n",
    "            # Use logsumexp for numerical stability\n",
    "            next_tag_var = torch.logsumexp(next_tag_var, dim=1)  # (batch_size, num_tags)\n",
    "            \n",
    "            # Apply mask\n",
    "            forward_var = torch.where(mask[:, i].unsqueeze(1), next_tag_var, forward_var)\n",
    "        \n",
    "        # Sum over all possible ending tags\n",
    "        terminal_var = torch.logsumexp(forward_var, dim=1)  # (batch_size,)\n",
    "        return terminal_var\n",
    "    \n",
    "    def _compute_score(self, emissions, tags, mask):\n",
    "        \"\"\"Compute the score of a given tag sequence\"\"\"\n",
    "        batch_size, seq_length = tags.size()\n",
    "        \n",
    "        # Compute emission scores\n",
    "        emission_scores = torch.gather(emissions, 2, tags.unsqueeze(2)).squeeze(2)\n",
    "        emission_scores = emission_scores * mask.float()\n",
    "        emission_scores = emission_scores.sum(dim=1)  # (batch_size,)\n",
    "        \n",
    "        # Compute transition scores\n",
    "        transition_scores = torch.zeros(batch_size, device=emissions.device)\n",
    "        \n",
    "        for i in range(seq_length - 1):\n",
    "            curr_tags = tags[:, i]\n",
    "            next_tags = tags[:, i + 1]\n",
    "            \n",
    "            # Get transition scores for valid positions\n",
    "            valid_mask = mask[:, i + 1]\n",
    "            trans_score = self.transitions[curr_tags, next_tags]\n",
    "            transition_scores += trans_score * valid_mask.float()\n",
    "        \n",
    "        return emission_scores + transition_scores\n",
    "    \n",
    "    def forward(self, emissions, tags, mask=None):\n",
    "        \"\"\"Compute CRF negative log likelihood\"\"\"\n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(tags, dtype=torch.bool)\n",
    "        \n",
    "        # Compute partition function (normalizer)\n",
    "        partition = self._compute_partition_function(emissions, mask)\n",
    "        \n",
    "        # Compute score of the given sequence\n",
    "        sequence_score = self._compute_score(emissions, tags, mask)\n",
    "        \n",
    "        # Return negative log likelihood\n",
    "        return (partition - sequence_score).mean()\n",
    "    \n",
    "    def decode(self, emissions, mask=None):\n",
    "        \"\"\"Viterbi decoding to find the best sequence\"\"\"\n",
    "        if mask is None:\n",
    "            mask = torch.ones(emissions.size()[:2], dtype=torch.bool, device=emissions.device)\n",
    "        \n",
    "        batch_size, seq_length, num_tags = emissions.size()\n",
    "        \n",
    "        # Initialize\n",
    "        viterbi_vars = emissions[:, 0].clone()  # (batch_size, num_tags)\n",
    "        path_scores = []\n",
    "        \n",
    "        # Forward pass\n",
    "        for i in range(1, seq_length):\n",
    "            broadcast_vars = viterbi_vars.unsqueeze(2)  # (batch_size, num_tags, 1)\n",
    "            broadcast_trans = self.transitions.unsqueeze(0)  # (1, num_tags, num_tags)\n",
    "            next_tag_vars = broadcast_vars + broadcast_trans\n",
    "            \n",
    "            # Find best previous tags\n",
    "            best_tag_scores, best_tags = torch.max(next_tag_vars, dim=1)\n",
    "            path_scores.append(best_tags)\n",
    "            \n",
    "            # Add emission scores\n",
    "            best_tag_scores += emissions[:, i]\n",
    "            \n",
    "            # Apply mask\n",
    "            viterbi_vars = torch.where(mask[:, i].unsqueeze(1), best_tag_scores, viterbi_vars)\n",
    "        \n",
    "        # Backward pass to find best path\n",
    "        best_paths = []\n",
    "        \n",
    "        for batch_idx in range(batch_size):\n",
    "            # Find best final tag\n",
    "            seq_len = mask[batch_idx].sum().item()\n",
    "            if seq_len == 0:\n",
    "                best_paths.append([])\n",
    "                continue\n",
    "                \n",
    "            _, best_last_tag = torch.max(viterbi_vars[batch_idx], dim=0)\n",
    "            best_path = [best_last_tag.item()]\n",
    "            \n",
    "            # Backtrack\n",
    "            for i in range(len(path_scores) - 1, -1, -1):\n",
    "                if i + 1 < seq_len:\n",
    "                    best_last_tag = path_scores[i][batch_idx][best_last_tag]\n",
    "                    best_path.append(best_last_tag.item())\n",
    "            \n",
    "            # Reverse to get correct order\n",
    "            best_path.reverse()\n",
    "            \n",
    "            # Pad with zeros if necessary\n",
    "            while len(best_path) < seq_len:\n",
    "                best_path.append(0)\n",
    "            \n",
    "            best_paths.append(best_path[:seq_len])\n",
    "        \n",
    "        return best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e2d2c1-81d9-4ddd-8c92-ad8844f8332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM-CRF Model\n",
    "class BiLSTM_CRF_Enhanced(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BiLSTM_CRF_Enhanced, self).__init__()\n",
    "        self.config = config\n",
    "        self.pad_idx = PAD_IDX\n",
    "        \n",
    "        # Word embeddings\n",
    "        self.word_embedding = nn.Embedding(\n",
    "            config['vocab_size'], config['word_embed_dim'], padding_idx=self.pad_idx\n",
    "        )\n",
    "        \n",
    "        # POS embeddings\n",
    "        self.pos_embedding = nn.Embedding(\n",
    "            config['pos_vocab_size'], config['pos_embed_dim']\n",
    "        )\n",
    "        \n",
    "        # Character-level CNN for better OOV handling\n",
    "        self.char_embed_dim = 30\n",
    "        self.char_cnn = self._build_char_cnn()\n",
    "        \n",
    "        # BiLSTM layers\n",
    "        total_embed_dim = (config['word_embed_dim'] + \n",
    "                          config['pos_embed_dim'] + \n",
    "                          config['char_embed_dim'])\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=total_embed_dim,\n",
    "            hidden_size=config['hidden_dim'],\n",
    "            num_layers=config['num_layers'],\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=config['dropout'] if config['num_layers'] > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layer_norm = nn.LayerNorm(config['hidden_dim'] * 2)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "        \n",
    "        # Linear layer for emissions\n",
    "        self.hidden2tag = nn.Linear(\n",
    "            config['hidden_dim'] * 2, config['tag_vocab_size']\n",
    "        )\n",
    "        \n",
    "        # CRF layer\n",
    "        self.crf = CRF(config['tag_vocab_size'], batch_first=True)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _enhanced_char_cnn(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(self.char_embed_dim, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "            nn.Dropout(0.25)\n",
    "    )\n",
    "    \n",
    "    def _get_char_features(self, words):\n",
    "        \"\"\"Extract character-level features\"\"\"\n",
    "        batch_size, seq_len = words.size()\n",
    "        char_features = torch.zeros(batch_size, seq_len, self.config['char_embed_dim'], \n",
    "                                   device=words.device)\n",
    "        \n",
    "        # Simple character features\n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_len):\n",
    "                word_idx = words[i, j].item()\n",
    "                if word_idx != self.pad_idx:\n",
    "                    word = idx2word.get(word_idx, '<UNK>')\n",
    "                    # Simple character encoding (first few characters)\n",
    "                    for k, char in enumerate(word[:self.config['char_embed_dim']]):\n",
    "                        char_features[i, j, k] = ord(char) % 128\n",
    "        \n",
    "        return char_features\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights\"\"\"\n",
    "        # Initialize embeddings\n",
    "        nn.init.uniform_(self.word_embedding.weight, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.pos_embedding.weight, -0.1, 0.1)\n",
    "        \n",
    "        # Initialize LSTM\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "        \n",
    "        # Initialize linear layer\n",
    "        nn.init.xavier_uniform_(self.hidden2tag.weight)\n",
    "        nn.init.constant_(self.hidden2tag.bias, 0)\n",
    "    \n",
    "    def forward(self, words, pos, tags=None):\n",
    "        batch_size, seq_len = words.size()\n",
    "        \n",
    "        # Create mask\n",
    "        mask = (words != self.pad_idx)\n",
    "        \n",
    "        # Get embeddings\n",
    "        word_embeds = self.word_embedding(words)\n",
    "        pos_embeds = self.pos_embedding(pos)\n",
    "        char_features = self._get_char_features(words)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        embeds = torch.cat([word_embeds, pos_embeds, char_features], dim=2)\n",
    "        embeds = self.dropout(embeds)\n",
    "        \n",
    "        # BiLSTM\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = self.layer_norm(lstm_out)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Get emission scores\n",
    "        emissions = self.hidden2tag(lstm_out)\n",
    "        \n",
    "        if tags is not None:\n",
    "            # Training mode: return CRF loss\n",
    "            loss = self.crf(emissions, tags, mask)\n",
    "            return loss\n",
    "        else:\n",
    "            # Inference mode: return best sequence\n",
    "            best_paths = self.crf.decode(emissions, mask)\n",
    "            return best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2be9b7f-4c05-41f0-a36a-05e62f1e535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 8,724,417\n"
     ]
    }
   ],
   "source": [
    "# Model Configuration and Initialization\n",
    "CONFIG = {\n",
    "    'vocab_size': len(word2idx),\n",
    "    'pos_vocab_size': len(pos2idx),\n",
    "    'tag_vocab_size': len(tag2idx),\n",
    "    'word_embed_dim': 150,\n",
    "    'pos_embed_dim': 25,\n",
    "    'char_embed_dim': 50,\n",
    "    'hidden_dim': 300,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'learning_rate': 0.002,\n",
    "    'num_epochs': 15,\n",
    "    'patience': 3,\n",
    "    'max_grad_norm': 5.0\n",
    "}\n",
    "\n",
    "model = BiLSTM_CRF_Enhanced(CONFIG).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fceeb3e5-4623-4bf6-9037-61d3ab77a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and Scheduler Setup\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=1e-4)\n",
    "\n",
    "# Warmup + Cosine decay scheduler\n",
    "steps_per_epoch = len(train_loader)\n",
    "total_steps = steps_per_epoch * CONFIG['num_epochs']\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return step / warmup_steps\n",
    "    progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9922b019-e8f8-4d89-9136-f77d51be7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Functions\n",
    "def train_epoch(model, train_loader, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1} [Train]', leave=False)\n",
    "    \n",
    "    for words, pos, tags in pbar:\n",
    "        words, pos, tags = words.to(device), pos.to(device), tags.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(words, pos, tags)\n",
    "        \n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            print(f\"Warning: Invalid loss detected: {loss}\")\n",
    "            continue\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['max_grad_norm'])\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'LR': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / num_batches if num_batches > 0 else 0\n",
    "\n",
    "def evaluate_model(model, val_loader, epoch):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc=f'Epoch {epoch+1} [Val]', leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for words, pos, tags in pbar:\n",
    "            words, pos, tags = words.to(device), pos.to(device), tags.to(device)\n",
    "            \n",
    "            # Get loss\n",
    "            model.train()\n",
    "            loss = model(words, pos, tags)\n",
    "            if not (torch.isnan(loss) or torch.isinf(loss)):\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "            \n",
    "            # Get predictions\n",
    "            model.eval()\n",
    "            predictions = model(words, pos)\n",
    "            \n",
    "            # Process predictions and targets\n",
    "            mask = (words != PAD_IDX).cpu().numpy()\n",
    "            tags_cpu = tags.cpu().numpy()\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                seq_len = int(mask[i].sum())\n",
    "                if seq_len > 0 and i < len(predictions):\n",
    "                    pred_seq = predictions[i][:seq_len]\n",
    "                    true_seq = tags_cpu[i][:seq_len]\n",
    "                    \n",
    "                    all_predictions.extend(pred_seq)\n",
    "                    all_targets.extend(true_seq.tolist())\n",
    "    \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    if len(all_predictions) > 0 and len(all_targets) > 0:\n",
    "        accuracy = np.mean(np.array(all_predictions) == np.array(all_targets))\n",
    "        f1 = f1_score(all_targets, all_predictions, average='weighted', zero_division=0)\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        f1 = 0.0\n",
    "    \n",
    "    return avg_loss, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca1bcff-3e86-43f3-a283-10e25319935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.7835\n",
      "Val Loss: 3.4974, Val Accuracy: 0.9541, Val F1: 0.9529\n",
      "Learning Rate: 1.33e-03\n",
      "✓ Best model saved! Val F1: 0.9529\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.4995\n",
      "Val Loss: 1.9386, Val Accuracy: 0.9689, Val F1: 0.9683\n",
      "Learning Rate: 1.99e-03\n",
      "✓ Best model saved! Val F1: 0.9683\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6199\n",
      "Val Loss: 1.7045, Val Accuracy: 0.9707, Val F1: 0.9698\n",
      "Learning Rate: 1.94e-03\n",
      "✓ Best model saved! Val F1: 0.9698\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3517\n",
      "Val Loss: 1.5695, Val Accuracy: 0.9707, Val F1: 0.9701\n",
      "Learning Rate: 1.84e-03\n",
      "✓ Best model saved! Val F1: 0.9701\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2241\n",
      "Val Loss: 1.5146, Val Accuracy: 0.9717, Val F1: 0.9709\n",
      "Learning Rate: 1.69e-03\n",
      "✓ Best model saved! Val F1: 0.9709\n",
      "\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1228\n",
      "Val Loss: 1.4875, Val Accuracy: 0.9705, Val F1: 0.9702\n",
      "Learning Rate: 1.50e-03\n",
      "No improvement. Patience: 1/4\n",
      "\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0482\n",
      "Val Loss: 1.4578, Val Accuracy: 0.9709, Val F1: 0.9707\n",
      "Learning Rate: 1.29e-03\n",
      "No improvement. Patience: 2/4\n",
      "\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m train_loss = train_epoch(model, train_loader, optimizer, scheduler, epoch)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m val_loss, val_accuracy, val_f1 = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Store metrics\u001b[39;00m\n\u001b[32m     23\u001b[39m train_losses.append(train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, val_loader, epoch)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Get loss\u001b[39;00m\n\u001b[32m     48\u001b[39m model.train()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (torch.isnan(loss) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(loss)):\n\u001b[32m     51\u001b[39m     total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/ML/Projects/ai-powered-research-assistant/assistant-gpu/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/ML/Projects/ai-powered-research-assistant/assistant-gpu/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mBiLSTM_CRF_Enhanced.forward\u001b[39m\u001b[34m(self, words, pos, tags)\u001b[39m\n\u001b[32m    105\u001b[39m word_embeds = \u001b[38;5;28mself\u001b[39m.word_embedding(words)\n\u001b[32m    106\u001b[39m pos_embeds = \u001b[38;5;28mself\u001b[39m.pos_embedding(pos)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m char_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_char_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Concatenate embeddings\u001b[39;00m\n\u001b[32m    110\u001b[39m embeds = torch.cat([word_embeds, pos_embeds, char_features], dim=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mBiLSTM_CRF_Enhanced._get_char_features\u001b[39m\u001b[34m(self, words)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq_len):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         word_idx = \u001b[43mwords\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m word_idx != \u001b[38;5;28mself\u001b[39m.pad_idx:\n\u001b[32m     72\u001b[39m             word = idx2word.get(word_idx, \u001b[33m'\u001b[39m\u001b[33m<UNK>\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training Loop with Early Stopping\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Training tracking\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_f1_scores = []\n",
    "best_f1 = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_accuracy, val_f1 = evaluate_model(model, val_loader, epoch)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1_scores.append(val_f1)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "    print(f\"Learning Rate: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    \n",
    "    # Early stopping based on F1 score\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'val_f1': val_f1,\n",
    "            'config': CONFIG,\n",
    "            'vocabularies': {\n",
    "                'word2idx': word2idx,\n",
    "                'pos2idx': pos2idx,\n",
    "                'tag2idx': tag2idx,\n",
    "                'idx2word': idx2word,\n",
    "                'idx2pos': idx2pos,\n",
    "                'idx2tag': idx2tag\n",
    "            }\n",
    "        }, os.path.join(MODEL_DIR, 'best_ner_model.pt'))\n",
    "        \n",
    "        print(f\"✓ Best model saved! Val F1: {val_f1:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "        \n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "print(f\"Best validation F1: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883dfad4-9da0-4deb-98d9-be11d179ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(val_losses, label='Val Loss', color='red')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(val_accuracies, label='Val Accuracy', color='green')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# F1 score plot\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(val_f1_scores, label='Val F1', color='purple')\n",
    "plt.title('Validation F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcabfcd0-2613-4fc3-b30b-75d1fc2b5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total epochs completed: {len(train_losses)}\")\n",
    "print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final val loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Final val accuracy: {val_accuracies[-1]:.4f}\")\n",
    "print(f\"Final val F1: {val_f1_scores[-1]:.4f}\")\n",
    "print(f\"Best val F1: {best_f1:.4f}\")\n",
    "print(f\"Training time: {total_time:.2f} seconds\")\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "print(f\"Model saved to: {os.path.join(MODEL_DIR, 'best_ner_model.pt')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df736eb4-d6c8-4497-9482-98401b82e43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
