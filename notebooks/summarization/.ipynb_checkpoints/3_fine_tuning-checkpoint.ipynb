{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc7da7b-a43e-4836-b0d2-12adb897280b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc99dbb9-a8d8-4470-a428-d6b0b502d85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = '../../data/summarization/'\n",
    "MODEL_DIR = '../../models/summarization/'\n",
    "VOCAB_PATH = os.path.join(MODEL_DIR, 'vocab.json')\n",
    "CHECKPOINT_PATH = os.path.join(MODEL_DIR, 'best_summarization_model.pt')\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d274a15b-8b2d-4b03-bc3f-d0fc2f3922ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "MAX_ARTICLE_LEN = 400\n",
    "MAX_SUMMARY_LEN = 50\n",
    "EMBEDDING_DIM = 256\n",
    "NUM_HEADS = 8\n",
    "FF_DIM = 512\n",
    "NUM_LAYERS = 4\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 3\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1633b36-16d9-434f-bcab-90247dd2d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab with size: 30000\n",
      "PAD token index: 0\n"
     ]
    }
   ],
   "source": [
    "# Load Vocabulary\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "# Tokens\n",
    "PAD_TOKEN   = '<PAD>'\n",
    "UNK_TOKEN   = '<UNK>'\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN   = '<END>'\n",
    "pad_idx = vocab[PAD_TOKEN]\n",
    "print(f\"Loaded vocab with size: {len(vocab)}\")\n",
    "print(f\"PAD token index: {pad_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de99ecb6-9422-487f-ae06-7a1c6da37f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, df, vocab, max_article_len=MAX_ARTICLE_LEN, max_summary_len=MAX_SUMMARY_LEN):\n",
    "        self.articles = df['clean_article'].values\n",
    "        self.summaries = df['clean_summary'].values\n",
    "        self.vocab = vocab\n",
    "        self.max_article_len = max_article_len\n",
    "        self.max_summary_len = max_summary_len\n",
    "\n",
    "    def encode(self, text, max_len, add_specials=False):\n",
    "        tokens = tokenize(text)\n",
    "        if add_specials:\n",
    "            tokens = [START_TOKEN] + tokens[:max_len-2] + [END_TOKEN]\n",
    "        else:\n",
    "            tokens = tokens[:max_len]\n",
    "        ids = [self.vocab.get(w, self.vocab[UNK_TOKEN]) for w in tokens]\n",
    "        if len(ids) < max_len:\n",
    "            ids += [self.vocab[PAD_TOKEN]] * (max_len - len(ids))\n",
    "        return ids[:max_len]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = torch.tensor(self.encode(self.articles[idx], self.max_article_len, add_specials=False), dtype=torch.long)\n",
    "        tgt = torch.tensor(self.encode(self.summaries[idx], self.max_summary_len, add_specials=True), dtype=torch.long)\n",
    "        return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83969dc3-4f07-41fd-8dfc-461740a7e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1515 | Val batches: 268\n"
     ]
    }
   ],
   "source": [
    "# Load train & val DataFrames\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'processed_train_split.csv'))\n",
    "val_df = pd.read_csv(os.path.join(DATA_DIR, 'processed_val_split.csv'))\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = SummarizationDataset(train_df, vocab, MAX_ARTICLE_LEN, MAX_SUMMARY_LEN)\n",
    "val_dataset   = SummarizationDataset(val_df, vocab, MAX_ARTICLE_LEN, MAX_SUMMARY_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc2b900-0907-43b5-97fb-1583ddc08593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransformerSummarizer Model Class Definition\n",
    "class TransformerSummarizer(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, nhead, ff_dim, num_layers, max_article_len, max_summary_len, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
    "        self.pos_encoder = nn.Embedding(max_article_len, emb_dim)\n",
    "        self.pos_decoder = nn.Embedding(max_summary_len, emb_dim)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(emb_dim, vocab_size)\n",
    "        self.max_article_len = max_article_len\n",
    "        self.max_summary_len = max_summary_len\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = None\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "        src_pos = self.pos_encoder(torch.arange(self.max_article_len, device=src.device)).unsqueeze(0)\n",
    "        tgt_pos = self.pos_decoder(torch.arange(self.max_summary_len, device=tgt.device)).unsqueeze(0)\n",
    "        \n",
    "        src_emb = self.embedding(src) + src_pos[:, :src.size(1), :]\n",
    "        tgt_emb = self.embedding(tgt) + tgt_pos[:, :tgt.size(1), :]\n",
    "        \n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        return self.fc_out(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62c0ca4-476f-4dd7-b1d2-61064e1fc079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Model and Load Checkpoint\n",
    "model = TransformerSummarizer(\n",
    "    vocab_size=len(vocab),\n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    nhead=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_article_len=MAX_ARTICLE_LEN,\n",
    "    max_summary_len=MAX_SUMMARY_LEN,\n",
    "    pad_idx=pad_idx\n",
    ").to(device)\n",
    "\n",
    "# Load checkpoint\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))\n",
    "    print(\"Checkpoint loaded successfully.\")\n",
    "else:\n",
    "    print(\"No checkpoint found; training from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae97a972-bc9e-4c68-b328-166c29b1940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer, criterion, scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac74e37f-fcdb-437d-98cd-f00816424a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying checkpoint loading...\n",
      "Initial validation loss after loading checkpoint: 4.8626\n",
      "Expected to be around 4.8632 from training\n"
     ]
    }
   ],
   "source": [
    "# VERIFY checkpoint loading by checking validation loss BEFORE fine-tuning\n",
    "print(\"Verifying checkpoint loading...\")\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for src, tgt in val_loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output = output.reshape(-1, output.shape[-1])\n",
    "        target = tgt[:, 1:].reshape(-1)\n",
    "        loss = criterion(output, target)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "initial_val_loss = val_loss / len(val_loader)\n",
    "print(f\"Initial validation loss after loading checkpoint: {initial_val_loss:.4f}\")\n",
    "print(f\"Expected to be around 4.8632 from training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee200a0c-e80f-407e-a640-c9e4b2596a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=4.1774 | Val Loss=4.8435\n",
      "--> New best model saved at epoch 1 with val loss 4.8435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=4.1386 | Val Loss=4.8478\n",
      "Validation loss did not improve. Early stopping count: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=4.1064 | Val Loss=4.8442\n",
      "Validation loss did not improve. Early stopping count: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=4.0775 | Val Loss=4.8485\n",
      "Validation loss did not improve. Early stopping count: 3/3\n",
      "Early stopping triggered. Finishing training.\n",
      "Fine-tuning complete. Best validation loss: 4.8435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Fine-tuning Loop with Early Stopping\n",
    "print(\"Starting fine-tuning...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch + 1} [Train]\", leave=False):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output = output.reshape(-1, output.shape[-1])\n",
    "        target = tgt[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(val_loader, desc=f\"Epoch {epoch + 1} [Val]\", leave=False):\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            output = model(src, tgt[:, :-1])\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            target = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss={avg_train_loss:.4f} | Val Loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping and checkpointing\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "        print(f\"--> New best model saved at epoch {epoch + 1} with val loss {best_val_loss:.4f}\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"Validation loss did not improve. Early stopping count: {counter}/{PATIENCE}\")\n",
    "        if counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered. Finishing training.\")\n",
    "            break\n",
    "\n",
    "print(f\"Fine-tuning complete. Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afcc427-29b8-4777-8ccc-bba332d0b564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
