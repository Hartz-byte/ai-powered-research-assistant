{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61bda73-e15c-46bf-ac53-fac4a5e3babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "499709fd-2573-4d98-93ec-4568508c3d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU device selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01120fc4-f94f-4cf3-a4f2-a8e6a1df4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed splits\n",
    "train_df = pd.read_csv('../../data/summarization/processed_train_split.csv')\n",
    "val_df = pd.read_csv('../../data/summarization/processed_val_split.csv')\n",
    "\n",
    "save_path = '../../models/summarization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ad17034-60e1-44fd-afc5-9c326333e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "def tokenize(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43903530-8227-4ef9-a1aa-f94abcf3f4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab saved to: ../../models/summarization/vocab.json\n",
      "Vocab size: 50000\n"
     ]
    }
   ],
   "source": [
    "# Build vocab\n",
    "def build_vocab(samples, min_freq=2, max_vocab_size=50000):\n",
    "    counter = Counter()\n",
    "    for text in samples:\n",
    "        counter.update(tokenize(text))\n",
    "    vocab = [w for w, f in counter.items() if f >= min_freq][:max_vocab_size-2]\n",
    "    word2idx = {w: i+2 for i, w in enumerate(vocab)}\n",
    "    word2idx['<PAD>'] = 0\n",
    "    word2idx['<UNK>'] = 1\n",
    "    return word2idx\n",
    "\n",
    "# Joint vocab from both articles and summaries\n",
    "combined_text = list(train_df['clean_article']) + list(train_df['clean_highlights'])\n",
    "vocab = build_vocab(combined_text)\n",
    "\n",
    "# Save vocab\n",
    "vocab_file = os.path.join(save_path, 'vocab.json')\n",
    "with open(vocab_file, 'w') as f:\n",
    "    json.dump(vocab, f)\n",
    "    \n",
    "print(f\"Vocab saved to: {vocab_file}\")\n",
    "print(f\"Vocab size: {len(vocab)}\")\n",
    "\n",
    "article_vocab = vocab\n",
    "summary_vocab = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d6655a3-bd68-49b1-bccd-aa19b2098868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, df, article_vocab, summary_vocab, max_article_len=400, max_summary_len=50):\n",
    "        self.articles = df['clean_article'].values\n",
    "        self.summaries = df['clean_highlights'].values\n",
    "        self.article_vocab = article_vocab\n",
    "        self.summary_vocab = summary_vocab\n",
    "        self.max_article_len = max_article_len\n",
    "        self.max_summary_len = max_summary_len\n",
    "\n",
    "    def encode(self, text, vocab, max_len):\n",
    "        tokens = tokenize(text)\n",
    "        ids = [vocab.get(w, vocab['<UNK>']) for w in tokens][:max_len]\n",
    "        ids += [vocab['<PAD>']] * (max_len - len(ids))\n",
    "        return ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = torch.tensor(self.encode(self.articles[idx], self.article_vocab, self.max_article_len), dtype=torch.long)\n",
    "        tgt = torch.tensor(self.encode(self.summaries[idx], self.summary_vocab, self.max_summary_len), dtype=torch.long)\n",
    "        return src, tgt\n",
    "\n",
    "train_data = SummarizationDataset(train_df, vocab, vocab)\n",
    "val_data = SummarizationDataset(val_df, vocab, vocab)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7afd4355-1c6a-4dd0-8030-6db2e34152e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline seq2seq model with LSTM\n",
    "class Seq2SeqBaseline(nn.Module):\n",
    "    def __init__(self, input_vocab_size, target_vocab_size, emb_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.encoder_emb = nn.Embedding(input_vocab_size, emb_dim, padding_idx=0)\n",
    "        self.encoder_lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.decoder_emb = nn.Embedding(target_vocab_size, emb_dim, padding_idx=0)\n",
    "        self.decoder_lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, target_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        _, (hidden, cell) = self.encoder_lstm(self.encoder_emb(src))\n",
    "        decoder_outputs, _ = self.decoder_lstm(self.decoder_emb(tgt), (hidden, cell))\n",
    "        logits = self.fc_out(decoder_outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03383fa8-b623-4dc6-bc7b-40179910e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and training setup\n",
    "input_vocab_size = len(article_vocab)\n",
    "target_vocab_size = len(summary_vocab)\n",
    "model = Seq2SeqBaseline(input_vocab_size, target_vocab_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ac1012-3aa1-490b-bd1d-eb2815661f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████| 1515/1515 [02:44<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Completed — Avg Loss: 6.5584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████| 1515/1515 [02:45<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Completed — Avg Loss: 5.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████████████████| 1515/1515 [02:49<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Completed — Avg Loss: 5.5072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████████████████████████████| 1515/1515 [02:48<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Completed — Avg Loss: 5.2372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████████████████████████████████████| 1515/1515 [02:51<00:00,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Completed — Avg Loss: 5.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(5):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output = output.reshape(-1, output.shape[-1])\n",
    "        target = tgt[:, 1:].reshape(-1)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            output = model(src, tgt[:, :-1])\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            target = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} — Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dc9c430-7a3d-441d-8405-3cb6ca8f8ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'best_summarization_model.pt'))\n",
    "\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921741a7-16e7-43c5-986f-1a8a0f6c9acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
