{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61bda73-e15c-46bf-ac53-fac4a5e3babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499709fd-2573-4d98-93ec-4568508c3d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01120fc4-f94f-4cf3-a4f2-a8e6a1df4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and tokens\n",
    "DATA_DIR = '../../data/summarization/'\n",
    "SAVE_DIR = '../../models/summarization/'\n",
    "VOCAB_PATH = os.path.join(SAVE_DIR, 'vocab.json')\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "PAD_TOKEN   = '<PAD>'\n",
    "UNK_TOKEN   = '<UNK>'\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN   = '<END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a52e067-eb8f-4c65-9e3b-d1c5700c79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'processed_train_split.csv'))\n",
    "val_df   = pd.read_csv(os.path.join(DATA_DIR, 'processed_val_split.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad17034-60e1-44fd-afc5-9c326333e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30000\n"
     ]
    }
   ],
   "source": [
    "# Vocab\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "def build_vocab(samples, min_freq=2, max_vocab_size=30000):\n",
    "    counter = Counter()\n",
    "    for text in samples:\n",
    "        counter.update(tokenize(text))\n",
    "    vocab = [PAD_TOKEN, UNK_TOKEN, START_TOKEN, END_TOKEN] + \\\n",
    "        [w for w, f in counter.items() if f >= min_freq][:max_vocab_size-4]\n",
    "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "    return word2idx\n",
    "\n",
    "combined_texts = list(train_df['clean_article']) + list(train_df['clean_summary'])\n",
    "vocab = build_vocab(combined_texts)\n",
    "\n",
    "with open(VOCAB_PATH, 'w') as f:\n",
    "    json.dump(vocab, f)\n",
    "print(f\"Vocab size: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1c4caf-7954-40b7-9f85-c0486011e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "MAX_ARTICLE_LEN = 400\n",
    "MAX_SUMMARY_LEN = 50\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_DIM = 256\n",
    "ENC_HIDDEN_DIM = 256\n",
    "DEC_HIDDEN_DIM = 256\n",
    "NUM_EPOCHS = 20\n",
    "PATIENCE = 3\n",
    "VOCAB_SIZE = len(vocab)\n",
    "NUM_HEADS = 8\n",
    "FF_DIM = 512\n",
    "NUM_LAYERS = 4\n",
    "SAVE_PATH = os.path.join(SAVE_DIR, 'best_summarization_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43903530-8227-4ef9-a1aa-f94abcf3f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & Loader\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, df, vocab, max_article_len=400, max_summary_len=50):\n",
    "        self.articles = df['clean_article'].values\n",
    "        self.summaries = df['clean_summary'].values\n",
    "        self.vocab = vocab\n",
    "        self.max_article_len = max_article_len\n",
    "        self.max_summary_len = max_summary_len\n",
    "\n",
    "    def encode(self, text, max_len, add_specials=False):\n",
    "        tokens = tokenize(text)\n",
    "        if add_specials:\n",
    "            tokens = [START_TOKEN] + tokens[:max_len-2] + [END_TOKEN]\n",
    "        else:\n",
    "            tokens = tokens[:max_len]\n",
    "        ids = [self.vocab.get(w, self.vocab[UNK_TOKEN]) for w in tokens]\n",
    "        if len(ids) < max_len:\n",
    "            ids += [self.vocab[PAD_TOKEN]] * (max_len - len(ids))\n",
    "        return ids[:max_len]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = torch.tensor(self.encode(self.articles[idx],  self.max_article_len, add_specials=False), dtype=torch.long)\n",
    "        tgt = torch.tensor(self.encode(self.summaries[idx], self.max_summary_len,  add_specials=True),  dtype=torch.long)\n",
    "        return src, tgt\n",
    "\n",
    "train_dataset = SummarizationDataset(train_df, vocab, MAX_ARTICLE_LEN, MAX_SUMMARY_LEN)\n",
    "val_dataset   = SummarizationDataset(val_df, vocab, MAX_ARTICLE_LEN, MAX_SUMMARY_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7afd4355-1c6a-4dd0-8030-6db2e34152e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model\n",
    "class TransformerSummarizer(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, nhead, ff_dim, num_layers, max_article_len, max_summary_len, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
    "        self.pos_encoder = nn.Embedding(max_article_len, emb_dim)\n",
    "        self.pos_decoder = nn.Embedding(max_summary_len, emb_dim)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(emb_dim, vocab_size)\n",
    "        self.max_article_len = max_article_len\n",
    "        self.max_summary_len = max_summary_len\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = None\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "        src_pos = self.pos_encoder(torch.arange(self.max_article_len, device=src.device)).unsqueeze(0)\n",
    "        tgt_pos = self.pos_decoder(torch.arange(self.max_summary_len, device=tgt.device)).unsqueeze(0)\n",
    "        src_emb = self.embedding(src) + src_pos[:, :src.size(1), :]\n",
    "        tgt_emb = self.embedding(tgt) + tgt_pos[:, :tgt.size(1), :]\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        return self.fc_out(outs)\n",
    "\n",
    "pad_idx = vocab[PAD_TOKEN]\n",
    "model = TransformerSummarizer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    nhead=NUM_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    max_article_len=MAX_ARTICLE_LEN,\n",
    "    max_summary_len=MAX_SUMMARY_LEN,\n",
    "    pad_idx=pad_idx\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min',\n",
    "    factor=0.5, patience=2,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03383fa8-b623-4dc6-bc7b-40179910e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 6.4991 | Val Loss: 6.0570\n",
      "--> New best model saved at epoch 1 with val loss 6.0570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 5.8925 | Val Loss: 5.7337\n",
      "--> New best model saved at epoch 2 with val loss 5.7337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 5.6341 | Val Loss: 5.5503\n",
      "--> New best model saved at epoch 3 with val loss 5.5503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 5.4555 | Val Loss: 5.4206\n",
      "--> New best model saved at epoch 4 with val loss 5.4206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 5.3142 | Val Loss: 5.3190\n",
      "--> New best model saved at epoch 5 with val loss 5.3190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 5.1942 | Val Loss: 5.2396\n",
      "--> New best model saved at epoch 6 with val loss 5.2396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 5.0888 | Val Loss: 5.1717\n",
      "--> New best model saved at epoch 7 with val loss 5.1717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 4.9926 | Val Loss: 5.1124\n",
      "--> New best model saved at epoch 8 with val loss 5.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Train]:   5%|███                                                             | 73/1515 [00:30<09:44,  2.47it/s]"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=False):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output = output.reshape(-1, output.shape[-1])\n",
    "        target = tgt[:, 1:].reshape(-1)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\", leave=False):\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            output = model(src, tgt[:, :-1])\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            target = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"--> New best model saved at epoch {epoch+1} with val loss {best_val_loss:.4f}\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"Validation loss did not improve. Early stopping counter: {counter}/{PATIENCE}\")\n",
    "        if counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered. Training halted.\")\n",
    "            break\n",
    "\n",
    "print(f\"Training complete. Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921741a7-16e7-43c5-986f-1a8a0f6c9acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
